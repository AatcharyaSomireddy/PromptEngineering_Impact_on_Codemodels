==========================================================================================
 AI CODE GENERATION BENCHMARK ANALYSIS
==========================================================================================
 Problem: Valid Parentheses
 Analysis Type: AI Models Only (No Template Systems)
 Total AI Experiments: 10
 Models Compared: starcoder-1b, codet5-small
 Analysis Date: 2025-10-30 14:00:59

 AI STRATEGY EFFECTIVENESS RANKING:
1. PERSONA             : 0.135029s average
2. FEW SHOT            : 0.161190s average
3. ZERO SHOT           : 0.302646s average
4. TEMPLATE            : 1.008796s average
5. COT                 : 1.244487s average

 AI MODEL PERFORMANCE RANKING:
1. STARCODER 1B        : 0.295854s average
2. CODET5 SMALL        : 0.845005s average

 AI TOKEN EFFICIENCY RANKING:
1. ZERO SHOT           : 28.0 tokens average
2. PERSONA             : 28.5 tokens average
3. COT                 : 29.5 tokens average
4. TEMPLATE            : 34.5 tokens average
5. FEW SHOT            : 52.5 tokens average

 KEY AI INSIGHTS:
  Best AI Strategy: Persona (0.135029s)
  Fastest AI Model: Starcoder 1B (0.295854s)
  Most Token Efficient: Zero Shot (28.0 tokens)
  AI Success Rate: 100.0%
  Performance Range: 19074993.9% difference between best and worst AI combinations

 RESEARCH IMPLICATIONS:
 This analysis compares only AI models for meaningful insights
 Template systems (local-stub) excluded for fair comparison
 Results show genuine AI model and strategy effectiveness

==========================================================================================